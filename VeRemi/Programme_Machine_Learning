# -*- coding: utf-8 -*-
"""
Created on Sat Mar 27 16:45:05 2021

@author: UPEC
"""

import time
import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
import seaborn as sns
from sklearn import preprocessing
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report,confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.decomposition import PCA
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
from sklearn import neighbors
import matplotlib.pyplot as plt
from sklearn.metrics import plot_confusion_matrix


df = pd.read_csv('VeReMi_SMOTE.csv')
X = df.drop('attackerType', axis=1)  
Y = df['attackerType']

def forest(X, Y):
    print('=================================================== RFC ================================================')
    X_Train, X_Test, Y_Train, Y_Test = train_test_split(X, Y, 
                                                        test_size = 0.25, 
                                                        random_state = 42)
    start = time.process_time()
    trainedforest = RandomForestClassifier(n_estimators = 125, max_depth = 50                                                                                         ).fit(X_Train,Y_Train)

    print(time.process_time() - start)
    predictionforest = trainedforest.predict(X_Test)
    print(confusion_matrix(Y_Test,predictionforest))
    print(classification_report(Y_Test,predictionforest))
    print("accuracy score : " , accuracy_score(Y_Test, predictionforest))
    clf =  RandomForestClassifier(n_estimators = 125, max_depth = 50)
    clf.fit(X_Train, Y_Train)
    plot_confusion_matrix(clf, X_Test, Y_Test)
    plt.title ('RF Confusion matrix')
    print('=================================================== FIN RFC ================================================')


def decisiontree(X,Y):
     print('=================================================== Decision Tree ================================================')
     X_Train, X_Test, Y_Train, Y_Test = train_test_split(X, Y, 
                                                        test_size = 0.25, 
                                                        random_state = 42)
     start= time.process_time()
     trained = DecisionTreeClassifier(min_samples_split=40, min_samples_leaf=10).fit(X_Train,Y_Train)
     print(print(time.process_time() - start))
     prediction = trained.predict(X_Test)
     print(confusion_matrix(Y_Test, prediction))
     print(classification_report(Y_Test,prediction))
     print("accuracy score : " , accuracy_score(Y_Test, prediction))
     # plot_confusion_matrix( trained, Y_Test, X_Test  )
     # plt.show()*
     clf = DecisionTreeClassifier(min_samples_split=40, min_samples_leaf=10)
     clf.fit(X_Train, Y_Train)
     plot_confusion_matrix(clf, X_Test, Y_Test)
     plt.show()
     plt.title ('Decision Tree Confusion matrix')
     print('=================================================== FIN Decision Tree ================================================')
     
def svm(X,Y):
        print('===================================================SVM================================================')
        X_Train, X_Test, Y_Train, Y_Test = train_test_split(X, Y, 
                                                        test_size = 0.25, 
                                                        random_state = 42)
        start = time.process_time()
        #mvs=svm.SVC()
        trainedsvm = SVC(random_state=1).fit(X_Train,Y_Train)
        print(time.process_time() - start)
        predictionsvm = trainedsvm.predict(X_Test)
        print(confusion_matrix(Y_Test,predictionsvm))
        print(classification_report(Y_Test,predictionsvm))
        plt.plot(confusion_matrix(Y_Test,predictionsvm))
        print('===============================================FIN SVM================================================')

def knn(X,Y):
        print('===================================================KNN================================================')
        X_Train, X_Test, Y_Train, Y_Test = train_test_split(X, Y, 
                                                        test_size = 0.25, 
                                                        random_state = 42)
        start = time.process_time()
        trainedknn = neighbors.KNeighborsClassifier(n_neighbors=8).fit(X_Train,Y_Train)
        print(time.process_time() - start)
        predictionknn = trainedknn.predict(X_Test)
        print(confusion_matrix(Y_Test,predictionknn))
        print(classification_report(Y_Test,predictionknn))
        print("accuracy score : " , accuracy_score(Y_Test, predictionknn))
        clf =  neighbors.KNeighborsClassifier(n_neighbors=8)
        clf.fit(X_Train, Y_Train)
        plot_confusion_matrix(clf, X_Test, Y_Test)
        plt.title ('KNN Confusion matrix')
        print('===================================================FIN KNN================================================')


def lr(X,Y):
        print('===================================================LR================================================')
        X_Train, X_Test, Y_Train, Y_Test = train_test_split(X, Y, 
                                                        test_size = 0.25, 
                                                        random_state = 42)
        start = time.process_time()
        trainedlr = LogisticRegression(random_state=1).fit(X_Train,Y_Train)
        print(time.process_time() - start)
        predictionlr = trainedlr.predict(X_Test)
        print(confusion_matrix(Y_Test,predictionlr))
        print(classification_report(Y_Test,predictionlr))
        print('===============================================FIN LR================================================')

def XG(X,Y):
    print('=================================================== XG ================================================')
    X_Train, X_Test, Y_Train, Y_Test = train_test_split(X, Y, 
                                                        test_size = 0.25, 
                                                        random_state = 42)
    start = time.process_time()
    trainedXG = XGBClassifier().fit(X_Train,Y_Train)
    print(time.process_time() - start)
    predictionXG = trainedXG.predict(X_Test)
    print(confusion_matrix(Y_Test,predictionXG))
    print(classification_report(Y_Test,predictionXG))
    clf =  XGBClassifier()
    clf.fit(X_Train, Y_Train)
    plot_confusion_matrix(clf, X_Test, Y_Test)
    plt.title ('XGBoost Confusion matrix')
    print('=================================================== FIN XG ================================================')

pca = PCA(n_components=4)
X_pca = pca.fit_transform(X)
PCA_df = pd.DataFrame(data = X_pca, columns = ['PC1', 'PC2','PC3','PC4'])
PCA_df = pd.concat([PCA_df, df['attackerType']], axis = 1)
#print(PCA_df.head())

classes = [0, 1, 2, 4, 8, 16]
for clas in classes :
    plt.scatter(PCA_df.loc[PCA_df['attackerType'] == clas, 'PC1'], 
                PCA_df.loc[PCA_df['attackerType'] == clas, 'PC2'],
                PCA_df.loc[PCA_df['attackerType'] == clas, 'PC3'], 
                PCA_df.loc[PCA_df['attackerType'] == clas, 'PC4'],)
                #PCA_df.loc[PCA_df['attackerType'] == clas, 'PC5'], )
                #PCA_df.loc[PCA_df['attackerType'] == clas, 'PC6'],)
                # PCA_df.loc[PCA_df['attackerType'] == clas, 'PC7'], 
                # PCA_df.loc[PCA_df['attackerType'] == clas, 'PC8'],)

plt.xlabel('Principal Component 1', fontsize = 12)
plt.ylabel('Principal Component 2', fontsize = 12)
plt.title('2D PCA', fontsize = 15)
plt.legend(['Normal', 'Attack_type_1', 'Attack_type_2', 'Attack_type_4', 'Attack_type_8', 'Attack_type_16'])
plt.grid()




#forest(X_pca, Y)

decisiontree(X_pca,Y)

#XG(X_pca,Y)

#knn(X_pca, Y)

#lr(X_pca,Y)

#svm(X_pca,Y)

